{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Système Multi-Agents avec Q-Learning - Démonstration Complète\n",
    "\n",
    "Ce notebook présente l'ensemble des fonctionnalités du système d'ordonnancement hospitalier.\n",
    "\n",
    "### Objectifs de la démonstration :\n",
    "1. **Visualisation des données** : Planning initial et contraintes.\n",
    "2. **Analyse de la Diversité** : Génération et affichage de la **Matrice des Distances** de l'EMP.\n",
    "3. **Benchmark Slide 25** : Comparaison Métaheuristiques Seules vs SMA (Tableau généré).\n",
    "4. **Benchmark Slide 26** : Comparaison Collaboration Amis vs Ennemis (Tableau généré).\n",
    "5. **Visualisation Finale** : Courbes de convergence et Gantt optimisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuration et Imports\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Ajout du chemin racine\n",
    "sys.path.insert(0, os.path.abspath(os.getcwd()))\n",
    "\n",
    "# Imports du Core\n",
    "from core.environment import create_default_environment\n",
    "from core.neighborhoods import NeighborhoodManager\n",
    "from core.shared_memory import SharedMemoryPool, Solution\n",
    "from core.agents import MultiAgentSystem, CollaborationMode\n",
    "from visualization import plot_gantt, plot_convergence\n",
    "\n",
    "# Configuration visuelle\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✓ Environnement chargé avec succès.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse de la Diversité (Matrice des Distances)\n",
    "\n",
    "L'Espace Mémoire Partagé (EMP) utilise une distance de Hamming adaptée pour maintenir la diversité. Visualisons cette matrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diversity_heatmap(emp, title=\"Matrice des Distances (Diversité EMP)\"):\n",
    "    \"\"\"Génère une heatmap des distances entre les solutions de l'EMP.\"\"\"\n",
    "    solutions = emp.solutions\n",
    "    n = len(solutions)\n",
    "    \n",
    "    if n < 2:\n",
    "        print(\"Pas assez de solutions pour afficher la matrice.\")\n",
    "        return\n",
    "\n",
    "    matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            # Calcul de la distance via la méthode interne de l'EMP\n",
    "            dist = emp.calculate_distance(solutions[i].sequences, solutions[j].sequences)\n",
    "            matrix[i, j] = dist\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cax = ax.imshow(matrix, cmap='viridis', interpolation='nearest')\n",
    "    fig.colorbar(cax, label='Distance de Hamming')\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Index Solution A\")\n",
    "    ax.set_ylabel(\"Index Solution B\")\n",
    "    plt.show()\n",
    "\n",
    "# Simulation : Remplissage de l'EMP avec des solutions aléatoires\n",
    "env = create_default_environment()\n",
    "temp_emp = SharedMemoryPool(max_size=20, min_distance=0, diversity_threshold=1.0)\n",
    "\n",
    "print(\"Génération de solutions pour la matrice de diversité...\")\n",
    "for i in range(15):\n",
    "    sol = env.build_initial_solution(random_order=True)\n",
    "    fit, _, _ = env.evaluate(sol)\n",
    "    temp_emp.insert(Solution(sol, fit))\n",
    "\n",
    "plot_diversity_heatmap(temp_emp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Benchmark - Tableau 1 (Slide 25)\n",
    "**Comparaison : Métaheuristiques Seules vs SMA**\n",
    "\n",
    "Nous lançons des exécutions courtes (50 itérations) pour générer les données du tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_quick_scenario(name, mode, q_learn, agents_config, iterations=50):\n",
    "    \"\"\"Exécute un scénario et retourne le meilleur makespan.\"\"\"\n",
    "    sys_local = MultiAgentSystem(env, mode=mode, use_qlearning=q_learn)\n",
    "    for type_ag, name_ag, params in agents_config:\n",
    "        sys_local.add_agent(type_ag, name_ag, **params)\n",
    "    \n",
    "    start = time.time()\n",
    "    best = sys_local.run(n_iterations=iterations, verbose=False)\n",
    "    dt = time.time() - start\n",
    "    return best.fitness if best else float('inf'), dt\n",
    "\n",
    "ITERATIONS = 50\n",
    "results_table_1 = {}\n",
    "\n",
    "print(f\"Lancement du Benchmark Tableau 1 ({ITERATIONS} itérations par run)...\")\n",
    "\n",
    "# 1. AG Solo\n",
    "res, t = run_quick_scenario(\"AG Solo\", CollaborationMode.ENEMIES, False, \n",
    "                            [('genetic', 'AG', {'population_size': 20})], ITERATIONS)\n",
    "results_table_1['AG'] = res\n",
    "\n",
    "# 2. Tabou Solo\n",
    "res, t = run_quick_scenario(\"Tabou Solo\", CollaborationMode.ENEMIES, False, \n",
    "                            [('tabu', 'Tabu', {'tabu_tenure': 10})], ITERATIONS)\n",
    "results_table_1['Tabu'] = res\n",
    "\n",
    "# 3. RS Solo\n",
    "res, t = run_quick_scenario(\"RS Solo\", CollaborationMode.ENEMIES, False, \n",
    "                            [('sa', 'RS', {'initial_temp': 100})], ITERATIONS)\n",
    "results_table_1['RS'] = res\n",
    "\n",
    "# Configuration SMA (Trio)\n",
    "trio_config = [\n",
    "    ('genetic', 'AG', {'population_size': 15}),\n",
    "    ('tabu', 'Tabu', {'tabu_tenure': 10}),\n",
    "    ('sa', 'RS', {'initial_temp': 100})\n",
    "]\n",
    "\n",
    "# 4. SMA No Learning\n",
    "res, t = run_quick_scenario(\"SMA NoLearn\", CollaborationMode.FRIENDS, False, trio_config, ITERATIONS)\n",
    "results_table_1['SMA_NoLearn'] = res\n",
    "\n",
    "# 5. SMA Learning\n",
    "res, t = run_quick_scenario(\"SMA Learn\", CollaborationMode.FRIENDS, True, trio_config, ITERATIONS)\n",
    "results_table_1['SMA_Learn'] = res\n",
    "\n",
    "# Affichage du Tableau 1\n",
    "print(\"\\n\" + \"=\"*75)\n",
    "print(\"  TABLEAU 1 : RÉSULTATS SANS/AVEC COLLABORATION (Inspiré Slide 25)\")\n",
    "print(\"=\"*75)\n",
    "print(f\"{'Configuration':<20} | {'Makespan Moyen (Score)':<25} | {'Gain Relatif'}\")\n",
    "print(\"-\"*75)\n",
    "base = results_table_1['AG']\n",
    "for key, val in results_table_1.items():\n",
    "    gain = ((base - val) / base) * 100\n",
    "    print(f\"{key:<20} | {val:<25.1f} | {gain:+.2f}%\")\n",
    "print(\"=\"*75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Benchmark - Tableau 2 (Slide 26)\n",
    "**Comparaison : Mode AMIS vs Mode ENNEMIS**\n",
    "\n",
    "Nous comparons l'efficacité de la collaboration (Partage EMP) vs la compétition (Pool Élite)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Lancement du Benchmark Tableau 2 (Comparaison Modes)...\")\n",
    "\n",
    "# Configuration pour récupérer l'historique de convergence\n",
    "mas_amis = MultiAgentSystem(env, mode=CollaborationMode.FRIENDS, use_qlearning=True)\n",
    "for type_ag, name_ag, params in trio_config:\n",
    "    mas_amis.add_agent(type_ag, name_ag, **params)\n",
    "\n",
    "mas_ennemis = MultiAgentSystem(env, mode=CollaborationMode.ENEMIES, use_qlearning=True)\n",
    "for type_ag, name_ag, params in trio_config:\n",
    "    mas_ennemis.add_agent(type_ag, name_ag + \"_E\", **params)\n",
    "\n",
    "# Exécution\n",
    "best_amis = mas_amis.run(n_iterations=100, verbose=False)\n",
    "best_ennemis = mas_ennemis.run(n_iterations=100, verbose=False)\n",
    "\n",
    "# Affichage Tableau 2\n",
    "score_amis = best_amis.fitness\n",
    "score_ennemis = best_ennemis.fitness\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  TABLEAU 2 : AMIS vs ENNEMIS (Inspiré Slide 26)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Mode':<20} | {'Meilleur Makespan':<20} | {'Amélioration'}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Mode ENNEMIS':<20} | {score_ennemis:<20.1f} | Reference\")\n",
    "gain_collab = ((score_ennemis - score_amis) / score_ennemis) * 100\n",
    "print(f\"{'Mode AMIS':<20} | {score_amis:<20.1f} | {gain_collab:+.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisations Finales\n",
    "\n",
    "1. **Courbes de Convergence** : Comparaison de la vitesse de descente entre Amis et Ennemis.\n",
    "2. **Gantt Final** : Le meilleur planning trouvé par le mode AMIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Courbes de convergence Comparatives\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# On récupère l'historique du meilleur agent de chaque système pour simplifier\n",
    "# (ou la fitness globale si stockée, ici on prend l'historique d'un agent représentatif)\n",
    "hist_amis = mas_amis.agents['AG'].fitness_history\n",
    "hist_ennemis = mas_ennemis.agents['AG_E'].fitness_history\n",
    "\n",
    "plt.plot(hist_amis, label='Mode AMIS (Collaboratif)', color='green', linewidth=2)\n",
    "plt.plot(hist_ennemis, label='Mode ENNEMIS (Compétitif)', color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.title(\"Comparaison de Convergence : Amis vs Ennemis\")\n",
    "plt.xlabel(\"Itérations\")\n",
    "plt.ylabel(\"Makespan (Cmax)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 2. Gantt Final\n",
    "final_cmax, final_times, _ = env.evaluate(best_amis.sequences, return_schedule=True)\n",
    "plot_gantt(\n",
    "    final_times, env.skills, env.num_patients,\n",
    "    title=f\"Meilleur Planning Trouvé (Mode AMIS, Cmax={final_cmax})\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
