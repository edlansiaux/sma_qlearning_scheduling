{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet SMA Santé : Optimisation Collaborative & Apprentissage par Renforcement\n",
    "\n",
    "Ce notebook implémente une solution complète pour le problème d'ordonnancement de patients en milieu hospitalier, en respectant les exigences suivantes :\n",
    "\n",
    "1. **Modélisation hypercubique** : Axe temps discrétisé (5 min), relâchement de la contrainte des boxes.\n",
    "2. **Stratégies Hybrides & SMA** : Agents métaheuristiques collaboratifs.\n",
    "3. **Diversité de l'EMP** : Espace Mémoire Partagé avec contrôle de diversité basé sur une distance matricielle.\n",
    "4. **Modes de collaboration** : Amis (partage de solutions) et Ennemis (compétition/perturbation).\n",
    "5. **Auto-adaptation** : Processus de Décision Markovien (PDM) pour le choix des voisinages.\n",
    "6. **Voisinages** : Implémentation des 5 mouvements (A, B, C, D, E).\n",
    "7. **Q-Learning** : Apprentissage de la meilleure stratégie de recherche.\n",
    "8. **Tableaux de résultats** : Génération des benchmarks correspondants aux slides 25 et 26."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environnement & Modélisation Hypercubique\n",
    "\n",
    "Définition des structures de données (Tâche, Solution) et de l'environnement de simulation.\n",
    "- **Temps** : Discrétisé en slots de 5 minutes.\n",
    "- **Solution** : Dictionnaire `(Patient, Opération) -> (Ressource, Temps)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, NamedTuple\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# Configuration globale : Discrétisation en intervalles de 5 minutes\n",
    "SLOT_DURATION = 5  \n",
    "\n",
    "class Task(NamedTuple):\n",
    "    id: int          \n",
    "    patient_id: int\n",
    "    op_order: int    # Ordre de l'opération (j)\n",
    "    skill_req: int   # Compétence requise (médecin/ressource)\n",
    "    duration: int    # En minutes\n",
    "\n",
    "class Solution:\n",
    "    \"\"\"\n",
    "    Représente une solution dans le modèle hypercubique.\n",
    "    Structure: dictionnaire mapping (Patient, Op) -> (Staff_ID, Start_Slot)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.schedule: Dict[Tuple[int, int], Tuple[int, int]] = {} \n",
    "        self.fitness: float = float('inf')\n",
    "        self.is_valid: bool = False\n",
    "\n",
    "class SchedulingEnvironment:\n",
    "    def __init__(self, data: Dict, skills: List[int], num_patients: int):\n",
    "        self.data = data \n",
    "        self.skills = skills\n",
    "        self.num_patients = num_patients\n",
    "        self.tasks: List[Task] = []\n",
    "        self.tasks_map: Dict[Tuple[int, int], Task] = {}\n",
    "        self._parse_data()\n",
    "\n",
    "    def _parse_data(self):\n",
    "        tid = 0\n",
    "        for pid, ops in self.data.items():\n",
    "            for order, task_list in ops.items():\n",
    "                if task_list:\n",
    "                    # On suppose une tâche principale par étape pour le modèle simplifié\n",
    "                    skill, dur = task_list[0]\n",
    "                    t = Task(tid, pid, order, skill, dur)\n",
    "                    self.tasks.append(t)\n",
    "                    self.tasks_map[(pid, order)] = t\n",
    "                    tid += 1\n",
    "\n",
    "    def duration_to_slots(self, minutes: int) -> int:\n",
    "        \"\"\"Convertit la durée en nombre de slots de 5 minutes.\"\"\"\n",
    "        return (minutes + SLOT_DURATION - 1) // SLOT_DURATION\n",
    "\n",
    "    def build_initial_solution(self) -> Solution:\n",
    "        \"\"\"Génère une solution aléatoire valide respectant les contraintes de précédence.\"\"\"\n",
    "        sol = Solution()\n",
    "        # Disponibilité des ressources (Staff -> premier slot libre)\n",
    "        staff_availability = {s: 0 for s in self.skills}\n",
    "        # Disponibilité des patients (Patient -> premier slot libre)\n",
    "        patient_availability = {p: 0 for p in range(1, self.num_patients + 1)}\n",
    "\n",
    "        # Tri aléatoire des tâches pour la diversité initiale\n",
    "        all_tasks = list(self.tasks)\n",
    "        random.shuffle(all_tasks)\n",
    "        # Tri partiel pour respecter grossièrement l'ordre des opérations\n",
    "        all_tasks.sort(key=lambda t: t.op_order)\n",
    "        \n",
    "        for t in all_tasks:\n",
    "            # Allocation d'une ressource (ici simplifiée : staff_req est l'ID du staff)\n",
    "            staff_id = t.skill_req \n",
    "            \n",
    "            duration_slots = self.duration_to_slots(t.duration)\n",
    "            \n",
    "            # Début au max des disponibilités (Patient dispo ET Médecin dispo)\n",
    "            start_time = max(patient_availability[t.patient_id], staff_availability.get(staff_id, 0))\n",
    "            \n",
    "            sol.schedule[(t.patient_id, t.op_order)] = (staff_id, start_time)\n",
    "            \n",
    "            finish_time = start_time + duration_slots\n",
    "            patient_availability[t.patient_id] = finish_time\n",
    "            staff_availability[staff_id] = finish_time\n",
    "            \n",
    "        self.evaluate(sol)\n",
    "        return sol\n",
    "\n",
    "    def evaluate(self, solution: Solution) -> float:\n",
    "        \"\"\"Calcule le Makespan (Cmax) en slots.\"\"\"\n",
    "        if not solution.schedule:\n",
    "            solution.fitness = float('inf')\n",
    "            return float('inf')\n",
    "            \n",
    "        max_slot = 0\n",
    "        for (pid, op), (staff, start) in solution.schedule.items():\n",
    "            task = self.tasks_map.get((pid, op))\n",
    "            if task:\n",
    "                end = start + self.duration_to_slots(task.duration)\n",
    "                if end > max_slot:\n",
    "                    max_slot = end\n",
    "        \n",
    "        solution.fitness = max_slot\n",
    "        solution.is_valid = True \n",
    "        return max_slot\n",
    "\n",
    "    def copy_solution(self, solution: Solution) -> Solution:\n",
    "        new_sol = Solution()\n",
    "        new_sol.schedule = solution.schedule.copy()\n",
    "        new_sol.fitness = solution.fitness\n",
    "        new_sol.is_valid = solution.is_valid\n",
    "        return new_sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Voisinages (Neighborhoods)\n",
    "\n",
    "Implémentation des 5 opérateurs de voisinage décrits dans le document :\n",
    "- **A** : Réassignation à un autre personnel.\n",
    "- **B** : Réassignation de tâches successives.\n",
    "- **C** : Insertion (Shift) dans le planning du même personnel.\n",
    "- **D** : Échange (Swap) entre deux personnels différents.\n",
    "- **E** : Échange (Swap) au sein du même personnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeighborhoodManager:\n",
    "    def __init__(self, env: SchedulingEnvironment):\n",
    "        self.env = env\n",
    "        # Liste des voisinages disponibles\n",
    "        self.moves = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "    def apply_move(self, solution: Solution, move_type: str) -> Solution:\n",
    "        new_sol = self.env.copy_solution(solution)\n",
    "        keys = list(new_sol.schedule.keys())\n",
    "        if not keys: return new_sol\n",
    "\n",
    "        # Sélection aléatoire d'une tâche source (i, j)\n",
    "        k1 = random.choice(keys)\n",
    "        staff1, start1 = new_sol.schedule[k1]\n",
    "        \n",
    "        # --- A: Assignment to different medical staff ---\n",
    "        if move_type == 'A':\n",
    "            other_staffs = [s for s in self.env.skills if s != staff1]\n",
    "            if other_staffs:\n",
    "                new_staff = random.choice(other_staffs)\n",
    "                new_sol.schedule[k1] = (new_staff, start1)\n",
    "\n",
    "        # --- B: Successive care tasks assignment ---\n",
    "        elif move_type == 'B':\n",
    "            k_next = (k1[0], k1[1] + 1)\n",
    "            if k_next in new_sol.schedule:\n",
    "                other_staffs = [s for s in self.env.skills if s != staff1]\n",
    "                if other_staffs:\n",
    "                    new_staff = random.choice(other_staffs)\n",
    "                    new_sol.schedule[k1] = (new_staff, start1)\n",
    "                    s2, t2 = new_sol.schedule[k_next]\n",
    "                    new_sol.schedule[k_next] = (new_staff, t2)\n",
    "\n",
    "        # --- C: Work schedule insertion (Shift/Move) ---\n",
    "        elif move_type == 'C':\n",
    "            shift = random.randint(-6, 6) # Décalage +/- 30 min\n",
    "            new_start = max(0, start1 + shift)\n",
    "            new_sol.schedule[k1] = (staff1, new_start)\n",
    "\n",
    "        # --- D: Swap two care tasks between different medical staff ---\n",
    "        elif move_type == 'D':\n",
    "            candidates = [k for k, v in new_sol.schedule.items() if v[0] != staff1]\n",
    "            if candidates:\n",
    "                k2 = random.choice(candidates)\n",
    "                staff2, start2 = new_sol.schedule[k2]\n",
    "                new_sol.schedule[k1] = (staff2, start1)\n",
    "                new_sol.schedule[k2] = (staff1, start2)\n",
    "\n",
    "        # --- E: Swap between the same medical staff member ---\n",
    "        elif move_type == 'E':\n",
    "            candidates = [k for k, v in new_sol.schedule.items() if v[0] == staff1 and k != k1]\n",
    "            if candidates:\n",
    "                k2 = random.choice(candidates)\n",
    "                staff2, start2 = new_sol.schedule[k2]\n",
    "                new_sol.schedule[k1] = (staff1, start2)\n",
    "                new_sol.schedule[k2] = (staff1, start1)\n",
    "\n",
    "        self.env.evaluate(new_sol)\n",
    "        return new_sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mémoire Partagée (EMP) & Diversité\n",
    "\n",
    "Gestion de l'espace mémoire commun pour la collaboration.\n",
    "- Calcul de la distance matricielle entre solutions.\n",
    "- **Algorithme 6** : Contrôle d'insertion basé sur le seuil de diversité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedMemory:\n",
    "    def __init__(self, max_size=20, min_dist=2, diversity_threshold=0.5):\n",
    "        self.solutions: List[Solution] = []\n",
    "        self.max_size = max_size \n",
    "        self.min_dist = min_dist \n",
    "        self.dt = diversity_threshold \n",
    "\n",
    "    def calculate_distance(self, sol1: Solution, sol2: Solution) -> int:\n",
    "        \"\"\"\n",
    "        Calcule la distance matricielle : Nombre de créneaux différents.\n",
    "        \"\"\"\n",
    "        dist = 0\n",
    "        all_keys = set(sol1.schedule.keys()) | set(sol2.schedule.keys())\n",
    "        for k in all_keys:\n",
    "            v1 = sol1.schedule.get(k)\n",
    "            v2 = sol2.schedule.get(k)\n",
    "            if v1 != v2: \n",
    "                dist += 1\n",
    "        return dist\n",
    "\n",
    "    def try_insert(self, cs: Solution) -> bool:\n",
    "        \"\"\"Algorithme 6: Contrôler la diversité de l'EMP.\"\"\"\n",
    "        nb = len(self.solutions)\n",
    "        \n",
    "        # Vérification doublon exact\n",
    "        for s in self.solutions:\n",
    "            if self.calculate_distance(cs, s) == 0:\n",
    "                return False\n",
    "\n",
    "        # Calculer le nombre de solutions 'différentes'\n",
    "        d_count = 0\n",
    "        for s in self.solutions:\n",
    "            if self.calculate_distance(cs, s) >= self.min_dist:\n",
    "                d_count += 1\n",
    "        \n",
    "        ratio = d_count / nb if nb > 0 else 1.0\n",
    "        inserted = False\n",
    "\n",
    "        if ratio >= self.dt:\n",
    "            if nb < self.max_size:\n",
    "                self.solutions.append(cs)\n",
    "                inserted = True\n",
    "            else:\n",
    "                worst_idx = self._get_worst_idx()\n",
    "                if worst_idx != -1 and cs.fitness < self.solutions[worst_idx].fitness:\n",
    "                     self.solutions.pop(worst_idx)\n",
    "                     self.solutions.append(cs)\n",
    "                     inserted = True\n",
    "        else:\n",
    "            worst_idx = self._get_worst_idx()\n",
    "            if nb >= self.max_size and worst_idx != -1 and cs.fitness < self.solutions[worst_idx].fitness:\n",
    "                self.solutions.pop(worst_idx)\n",
    "                self.solutions.append(cs)\n",
    "                inserted = True\n",
    "\n",
    "        if inserted:\n",
    "            self.solutions.sort(key=lambda x: x.fitness)\n",
    "            \n",
    "        return inserted\n",
    "\n",
    "    def _get_worst_idx(self):\n",
    "        if not self.solutions: return -1\n",
    "        vals = [s.fitness for s in self.solutions]\n",
    "        return vals.index(max(vals))\n",
    "\n",
    "    def get_best(self):\n",
    "        if not self.solutions: return None\n",
    "        return self.solutions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Q-Learning & Auto-Adaptation\n",
    "\n",
    "Implémentation du **Processus de Décision Markovien (MDP)** pour l'auto-adaptation des agents.\n",
    "- **États** : Amélioration (0), Stagnation (1), Dégradation (2).\n",
    "- **Actions** : Choix du voisinage (A, B, C, D, E).\n",
    "- **Récompense** : Différence de fitness.\n",
    "- **Mise à jour Q-Table** : Formule standard du Q-Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class QLearningModel:\n",
    "    def __init__(self, actions, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
    "        self.actions = actions \n",
    "        self.q_table = {} \n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.states = [0, 1, 2]\n",
    "        \n",
    "        for s in self.states:\n",
    "            self.q_table[s] = {a: 0.0 for a in actions}\n",
    "\n",
    "    def get_state(self, current_fit, prev_fit):\n",
    "        if prev_fit is None: return 1\n",
    "        if current_fit < prev_fit: return 0 # Amélioration\n",
    "        if current_fit == prev_fit: return 1 # Stagnation\n",
    "        return 2 # Dégradation\n",
    "\n",
    "    def select_action(self, state):\n",
    "        # Algorithme 4: SelectAction (e, b) - Epsilon-Greedy\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(self.actions) # Exploration\n",
    "        else:\n",
    "            items = list(self.q_table[state].items())\n",
    "            random.shuffle(items)\n",
    "            return max(items, key=lambda x: x[1])[0] # Exploitation\n",
    "\n",
    "    def update(self, state, action, reward, next_state):\n",
    "        current_q = self.q_table[state][action]\n",
    "        max_next_q = max(self.q_table[next_state].values())\n",
    "        \n",
    "        new_q = current_q + self.alpha * (reward + self.gamma * max_next_q - current_q)\n",
    "        self.q_table[state][action] = new_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agents & Système Multi-Agents (SMA)\n",
    "\n",
    "Définition des agents métaheuristiques (AG, Tabou, RS) et de leurs modes d'interaction :\n",
    "- **Amis** : Échange complet de solutions via l'EMP.\n",
    "- **Ennemis** : Accès limité au critère (fitness), stimulation par perturbation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaheuristicAgent:\n",
    "    def __init__(self, id, env, strategy_type, use_learning=True):\n",
    "        self.id = id\n",
    "        self.env = env\n",
    "        self.strategy_type = strategy_type \n",
    "        self.use_learning = use_learning\n",
    "        \n",
    "        self.current_solution = None\n",
    "        self.best_solution = None\n",
    "        \n",
    "        self.nm = NeighborhoodManager(env)\n",
    "        self.brain = QLearningModel(actions=self.nm.moves) if use_learning else None\n",
    "        self.last_fitness = None\n",
    "\n",
    "    def initialize(self):\n",
    "        self.current_solution = self.env.build_initial_solution()\n",
    "        self.best_solution = self.env.copy_solution(self.current_solution)\n",
    "        self.last_fitness = self.current_solution.fitness\n",
    "\n",
    "    def step(self, emp: SharedMemory, collaboration_mode: str):\n",
    "        # 1. Collaboration\n",
    "        if collaboration_mode == 'FRIENDS':\n",
    "            best_shared = emp.get_best()\n",
    "            if best_shared and best_shared.fitness < self.current_solution.fitness:\n",
    "                if random.random() < 0.2: \n",
    "                    self.current_solution = self.env.copy_solution(best_shared)\n",
    "\n",
    "        elif collaboration_mode == 'ENEMIES':\n",
    "            best_shared = emp.get_best()\n",
    "            if best_shared and best_shared.fitness < self.current_solution.fitness:\n",
    "                 # Perturbation majeure si un 'ennemi' fait mieux\n",
    "                 self.current_solution = self.nm.apply_move(self.current_solution, 'A')\n",
    "\n",
    "        # 2. Choix Action (Auto-adaptation)\n",
    "        state = 1\n",
    "        action = 'C'\n",
    "        if self.use_learning:\n",
    "            state = self.brain.get_state(self.current_solution.fitness, self.last_fitness)\n",
    "            action = self.brain.select_action(state)\n",
    "        else:\n",
    "            if self.strategy_type == 'AG': action = random.choice(['A', 'B'])\n",
    "            elif self.strategy_type == 'Tabu': action = random.choice(['C', 'D'])\n",
    "            else: action = random.choice(['C', 'E'])\n",
    "\n",
    "        # 3. Application Mouvement\n",
    "        prev_fit = self.current_solution.fitness\n",
    "        new_sol = self.nm.apply_move(self.current_solution, action)\n",
    "        \n",
    "        # 4. Acceptation\n",
    "        accept = False\n",
    "        if new_sol.fitness <= prev_fit:\n",
    "            accept = True\n",
    "        elif self.strategy_type == 'RS' and random.random() < 0.1:\n",
    "            accept = True\n",
    "        \n",
    "        if accept:\n",
    "            self.current_solution = new_sol\n",
    "            if new_sol.fitness < self.best_solution.fitness:\n",
    "                self.best_solution = self.env.copy_solution(new_sol)\n",
    "                emp.try_insert(self.env.copy_solution(self.best_solution))\n",
    "\n",
    "        # 5. Update Q-Learning\n",
    "        if self.use_learning:\n",
    "            reward = prev_fit - new_sol.fitness \n",
    "            next_state = self.brain.get_state(new_sol.fitness, prev_fit)\n",
    "            self.brain.update(state, action, reward, next_state)\n",
    "            \n",
    "        self.last_fitness = self.current_solution.fitness\n",
    "        return self.best_solution.fitness\n",
    "\n",
    "class MultiAgentSystem:\n",
    "    def __init__(self, env, agents_config, mode='FRIENDS'):\n",
    "        self.env = env\n",
    "        self.emp = SharedMemory()\n",
    "        self.mode = mode\n",
    "        self.agents = []\n",
    "        for conf in agents_config:\n",
    "            self.agents.append(MetaheuristicAgent(conf['id'], env, conf['type'], conf['learning']))\n",
    "\n",
    "    def run(self, iterations=50):\n",
    "        for a in self.agents: a.initialize()\n",
    "        \n",
    "        history = []\n",
    "        for i in range(iterations):\n",
    "            step_res = []\n",
    "            for a in self.agents:\n",
    "                fit = a.step(self.emp, self.mode)\n",
    "                step_res.append(fit)\n",
    "            history.append(min(step_res))\n",
    "        \n",
    "        return min(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Génération des Résultats (Benchmark)\n",
    "\n",
    "Génération automatique des données et exécution des scénarios pour produire les tableaux comparatifs :\n",
    "- Sans Collaboration (Agents isolés vs SMA de base).\n",
    "- Avec Collaboration (Comparaison Amis vs Ennemis, avec et sans apprentissage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_data(num_patients=5, max_ops=3, skills=[1,2,3,4]):\n",
    "    data = {}\n",
    "    for i in range(1, num_patients+1):\n",
    "        data[i] = {}\n",
    "        for j in range(1, max_ops+1):\n",
    "            if random.random() > 0.1: \n",
    "                skill = random.choice(skills)\n",
    "                duration = random.randint(10, 60) \n",
    "                data[i][j] = [(skill, duration)]\n",
    "    return data\n",
    "\n",
    "def run_benchmark(num_patients=20, iterations=15):\n",
    "    print(f\"Génération des données pour {num_patients} patients...\")\n",
    "    skills = [1, 2, 3, 4]\n",
    "    data = generate_random_data(num_patients=num_patients, max_ops=4, skills=skills)\n",
    "    env = SchedulingEnvironment(data, skills, num_patients)\n",
    "\n",
    "    print(\"\\n--- Tableau de comparaison SANS collaboration (Slide 25) ---\")\n",
    "    print('\"Jour\",\"Patients\",,\"AG_Solo\",\"Tabou_Solo\",\"RS_Solo\",\"SMA_NoLearn\",\"SMA_Learn\"')\n",
    "\n",
    "    ag_solo = MultiAgentSystem(env, [{'id':'AG','type':'AG','learning':False}], mode='ENEMIES').run(iterations)\n",
    "    tabu_solo = MultiAgentSystem(env, [{'id':'Tabu','type':'Tabu','learning':False}], mode='ENEMIES').run(iterations)\n",
    "    rs_solo = MultiAgentSystem(env, [{'id':'RS','type':'RS','learning':False}], mode='ENEMIES').run(iterations)\n",
    "\n",
    "    sma_no_learn = MultiAgentSystem(env, [\n",
    "        {'id':'1','type':'AG','learning':False},\n",
    "        {'id':'2','type':'Tabu','learning':False},\n",
    "        {'id':'3','type':'RS','learning':False}\n",
    "    ], mode='FRIENDS').run(iterations)\n",
    "\n",
    "    sma_learn = MultiAgentSystem(env, [\n",
    "        {'id':'1','type':'AG','learning':True},\n",
    "        {'id':'2','type':'Tabu','learning':True},\n",
    "        {'id':'3','type':'RS','learning':True}\n",
    "    ], mode='FRIENDS').run(iterations)\n",
    "\n",
    "    print(f'\"J1\",\"{num_patients}\",,\"{ag_solo}\",\"{tabu_solo}\",\"{rs_solo}\",\"{sma_no_learn}\",\"{sma_learn}\"')\n",
    "\n",
    "    print(\"\\n\\n--- Tableau de comparaison AVEC collaboration (Slide 26) ---\")\n",
    "    print('\"SMA sans apprentissage (Amis)\",,,,,,\"SMA avec apprentissage (Ennemis)\"')\n",
    "    print('\"AG_Tabou\",\"AG_RS\",\"Tabou_RS\",,\"AG_Tabou\",\"AG_RS\",\"Tabou_RS\"')\n",
    "    \n",
    "    pairs = [\n",
    "        ([{'id':'1','type':'AG','learning':False},{'id':'2','type':'Tabu','learning':False}], 'FRIENDS'),\n",
    "        ([{'id':'1','type':'AG','learning':False},{'id':'3','type':'RS','learning':False}], 'FRIENDS'),\n",
    "        ([{'id':'2','type':'Tabu','learning':False},{'id':'3','type':'RS','learning':False}], 'FRIENDS'),\n",
    "        ([{'id':'1','type':'AG','learning':True},{'id':'2','type':'Tabu','learning':True}], 'ENEMIES'),\n",
    "        ([{'id':'1','type':'AG','learning':True},{'id':'3','type':'RS','learning':True}], 'ENEMIES'),\n",
    "        ([{'id':'2','type':'Tabu','learning':True},{'id':'3','type':'RS','learning':True}], 'ENEMIES'),\n",
    "    ]\n",
    "    \n",
    "    res = []\n",
    "    for conf, mode in pairs:\n",
    "        res.append(MultiAgentSystem(env, conf, mode=mode).run(iterations))\n",
    "        \n",
    "    print(f'\"{res[0]}\",\"{res[1]}\",\"{res[2]}\",,\"{res[3]}\",\"{res[4]}\",\"{res[5]}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lancement de la démonstration\n",
    "if __name__ == \"__main__\":\n",
    "    run_benchmark(num_patients=20, iterations=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
